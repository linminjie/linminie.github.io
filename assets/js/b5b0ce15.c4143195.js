"use strict";(globalThis.webpackChunkmimoe_devportal=globalThis.webpackChunkmimoe_devportal||[]).push([[6268],{1468(e,n,i){i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"ai-foundation/examples/semantic-search","title":"Semantic Search with Embeddings","description":"Build semantic search using embedding models on mimOE","source":"@site/docs/ai-foundation/examples/semantic-search.md","sourceDirName":"ai-foundation/examples","slug":"/ai-foundation/examples/semantic-search","permalink":"/mimOE-devportal/docs/ai-foundation/examples/semantic-search","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_position":4,"title":"Semantic Search with Embeddings","description":"Build semantic search using embedding models on mimOE"},"sidebar":"aiFoundationSidebar","previous":{"title":"Chat with SmolLM2","permalink":"/mimOE-devportal/docs/ai-foundation/examples/chat-smollm2"},"next":{"title":"Finding Models on Hugging Face","permalink":"/mimOE-devportal/docs/ai-foundation/examples/finding-models"}}');var s=i(4848),a=i(8453);const r={sidebar_position:4,title:"Semantic Search with Embeddings",description:"Build semantic search using embedding models on mimOE"},o="Semantic Search with Embeddings",d={},l=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step 1: Provision an Embedding Model",id:"step-1-provision-an-embedding-model",level:2},{value:"Step 2: Generate Embeddings",id:"step-2-generate-embeddings",level:2},{value:"Single Text",id:"single-text",level:3},{value:"Step 3: Build a Semantic Search Engine",id:"step-3-build-a-semantic-search-engine",level:2},{value:"JavaScript/Node.js",id:"javascriptnodejs",level:3},{value:"Python",id:"python",level:3},{value:"Step 4: Advanced Usage",id:"step-4-advanced-usage",level:2},{value:"RAG (Retrieval-Augmented Generation)",id:"rag-retrieval-augmented-generation",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Empty or Zero Embeddings",id:"empty-or-zero-embeddings",level:3},{value:"Slow Embedding Generation",id:"slow-embedding-generation",level:3},{value:"Different Embedding Dimensions",id:"different-embedding-dimensions",level:3},{value:"Next Steps",id:"next-steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"semantic-search-with-embeddings",children:"Semantic Search with Embeddings"})}),"\n",(0,s.jsx)(n.p,{children:"Build a semantic search system using embedding models. This example shows how to generate text embeddings and use them for similarity-based search."}),"\n",(0,s.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,s.jsx)(n.p,{children:"This example demonstrates:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Provisioning an embedding model (kind: ",(0,s.jsx)(n.code,{children:"embed"}),")"]}),"\n",(0,s.jsx)(n.li,{children:"Generating embeddings via the OpenAI-compatible API"}),"\n",(0,s.jsx)(n.li,{children:"Computing similarity between texts"}),"\n",(0,s.jsx)(n.li,{children:"Building a simple semantic search engine"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["mimOE AI Foundation Package running (",(0,s.jsx)(n.a,{href:"/mimOE-devportal/docs/ai-foundation/quick-start",children:"Quick Start"}),")"]}),"\n",(0,s.jsx)(n.li,{children:"Node.js 18+ or Python 3.8+ (for code examples)"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"step-1-provision-an-embedding-model",children:"Step 1: Provision an Embedding Model"}),"\n",(0,s.jsx)(n.p,{children:"Create the model metadata:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST "http://localhost:8083/mimik-ai/store/v1/models" \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer 1234" \\\n  -d \'{\n    "id": "nomic-embed-text",\n    "version": "1.0.0",\n    "kind": "embed",\n    "gguf": {\n      "initContextSize": 8192\n    }\n  }\'\n'})}),"\n",(0,s.jsx)(n.p,{children:"Download the model:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST "http://localhost:8083/mimik-ai/store/v1/models/nomic-embed-text/download" \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer 1234" \\\n  -d \'{\n    "url": "https://huggingface.co/nomic-ai/nomic-embed-text-v1.5-GGUF/resolve/main/nomic-embed-text-v1.5.Q8_0.gguf?download=true"\n  }\'\n'})}),"\n",(0,s.jsx)(n.p,{children:"Verify the model is ready:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl "http://localhost:8083/mimik-ai/store/v1/models/nomic-embed-text"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"step-2-generate-embeddings",children:"Step 2: Generate Embeddings"}),"\n",(0,s.jsx)(n.h3,{id:"single-text",children:"Single Text"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'curl -X POST "http://localhost:8083/mimik-ai/openai/v1/embeddings" \\\n  -H "Content-Type: application/json" \\\n  -H "Authorization: Bearer 1234" \\\n  -d \'{\n    "model": "nomic-embed-text",\n    "input": "What is machine learning?"\n  }\'\n'})}),"\n",(0,s.jsx)(n.p,{children:"Response:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-json",children:'{\n  "object": "list",\n  "data": [\n    {\n      "object": "embedding",\n      "index": 0,\n      "embedding": [0.0234, -0.0891, 0.0456, ...]\n    }\n  ],\n  "model": "nomic-embed-text",\n  "usage": {\n    "prompt_tokens": 5,\n    "total_tokens": 5\n  }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"step-3-build-a-semantic-search-engine",children:"Step 3: Build a Semantic Search Engine"}),"\n",(0,s.jsx)(n.h3,{id:"javascriptnodejs",children:"JavaScript/Node.js"}),"\n",(0,s.jsx)(n.p,{children:"Install the OpenAI SDK:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"npm install openai\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",metastring:'title="semantic-search.js"',children:"import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  baseURL: 'http://localhost:8083/mimik-ai/openai/v1',\n  apiKey: '1234'\n});\n\n// Sample document corpus\nconst documents = [\n  {\n    id: 1,\n    title: 'Introduction to Machine Learning',\n    content: 'Machine learning is a branch of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.'\n  },\n  {\n    id: 2,\n    title: 'Deep Learning Fundamentals',\n    content: 'Deep learning is a subset of machine learning that uses neural networks with multiple layers to progressively extract higher-level features from raw input.'\n  },\n  {\n    id: 3,\n    title: 'Natural Language Processing',\n    content: 'NLP is a field of AI focused on the interaction between computers and humans through natural language, enabling machines to understand and respond to text or voice data.'\n  },\n  {\n    id: 4,\n    title: 'Computer Vision Applications',\n    content: 'Computer vision is an AI field that trains computers to interpret and understand the visual world, using digital images from cameras and deep learning models.'\n  },\n  {\n    id: 5,\n    title: 'Reinforcement Learning',\n    content: 'Reinforcement learning is an area of ML where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.'\n  }\n];\n\n// Generate embeddings for one or more texts (batch limit: 50)\nasync function getEmbeddings(input) {\n  const response = await client.embeddings.create({\n    model: 'nomic-embed-text',\n    input\n  });\n  return response.data.map(d => d.embedding);\n}\n\n// Compute cosine similarity between two vectors\nfunction cosineSimilarity(a, b) {\n  let dotProduct = 0;\n  let normA = 0;\n  let normB = 0;\n\n  for (let i = 0; i < a.length; i++) {\n    dotProduct += a[i] * b[i];\n    normA += a[i] * a[i];\n    normB += b[i] * b[i];\n  }\n\n  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB));\n}\n\n// Semantic search class\nclass SemanticSearch {\n  constructor() {\n    this.documents = [];\n    this.embeddings = [];\n  }\n\n  async indexDocuments(docs) {\n    this.documents = docs;\n    console.log(`Indexing ${docs.length} documents...`);\n\n    // Batch embed all documents in a single request\n    this.embeddings = await getEmbeddings(docs.map(doc => doc.content));\n    console.log(`Indexed ${this.embeddings.length} documents`);\n  }\n\n  async search(query, topK = 3) {\n    // Get embedding for query\n    const [queryEmbedding] = await getEmbeddings(query);\n\n    // Calculate similarities\n    const similarities = this.embeddings.map((docEmbedding, index) => ({\n      document: this.documents[index],\n      similarity: cosineSimilarity(queryEmbedding, docEmbedding)\n    }));\n\n    // Sort by similarity and return top K\n    return similarities\n      .sort((a, b) => b.similarity - a.similarity)\n      .slice(0, topK);\n  }\n}\n\n// Demo\nasync function main() {\n  const search = new SemanticSearch();\n\n  // Index documents\n  await search.indexDocuments(documents);\n  console.log();\n\n  // Test queries\n  const queries = [\n    'How do neural networks work?',\n    'What is AI used for in images?',\n    'How can machines understand text?'\n  ];\n\n  for (const query of queries) {\n    console.log(`Query: \"${query}\"`);\n    console.log('-'.repeat(50));\n\n    const results = await search.search(query, 2);\n\n    for (const result of results) {\n      console.log(`  ${result.document.title}`);\n      console.log(`  Similarity: ${(result.similarity * 100).toFixed(1)}%`);\n      console.log();\n    }\n  }\n}\n\nmain().catch(console.error);\n"})}),"\n",(0,s.jsx)(n.p,{children:"Run with:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"node semantic-search.js\n"})}),"\n",(0,s.jsx)(n.h3,{id:"python",children:"Python"}),"\n",(0,s.jsx)(n.p,{children:"Install the OpenAI SDK:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install openai numpy\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",metastring:'title="semantic_search.py"',children:'from openai import OpenAI\nimport numpy as np\nfrom typing import List, Dict\n\nclient = OpenAI(\n    base_url="http://localhost:8083/mimik-ai/openai/v1",\n    api_key="1234"\n)\n\n# Sample document corpus\ndocuments = [\n    {\n        "id": 1,\n        "title": "Introduction to Machine Learning",\n        "content": "Machine learning is a branch of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed."\n    },\n    {\n        "id": 2,\n        "title": "Deep Learning Fundamentals",\n        "content": "Deep learning is a subset of machine learning that uses neural networks with multiple layers to progressively extract higher-level features from raw input."\n    },\n    {\n        "id": 3,\n        "title": "Natural Language Processing",\n        "content": "NLP is a field of AI focused on the interaction between computers and humans through natural language, enabling machines to understand and respond to text or voice data."\n    },\n    {\n        "id": 4,\n        "title": "Computer Vision Applications",\n        "content": "Computer vision is an AI field that trains computers to interpret and understand the visual world, using digital images from cameras and deep learning models."\n    },\n    {\n        "id": 5,\n        "title": "Reinforcement Learning",\n        "content": "Reinforcement learning is an area of ML where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward."\n    }\n]\n\ndef get_embeddings(input) -> List[List[float]]:\n    """Generate embeddings for one or more texts (batch limit: 50)."""\n    response = client.embeddings.create(\n        model="nomic-embed-text",\n        input=input\n    )\n    return [d.embedding for d in response.data]\n\ndef cosine_similarity(a: List[float], b: List[float]) -> float:\n    """Compute cosine similarity between two vectors."""\n    a = np.array(a)\n    b = np.array(b)\n    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n\nclass SemanticSearch:\n    def __init__(self):\n        self.documents = []\n        self.embeddings = []\n\n    def index_documents(self, docs: List[Dict]):\n        """Index documents by generating embeddings."""\n        self.documents = docs\n        print(f"Indexing {len(docs)} documents...")\n\n        # Batch embed all documents in a single request\n        self.embeddings = get_embeddings([doc["content"] for doc in docs])\n        print(f"Indexed {len(self.embeddings)} documents")\n\n    def search(self, query: str, top_k: int = 3) -> List[Dict]:\n        """Search for documents similar to the query."""\n        # Get embedding for query\n        [query_embedding] = get_embeddings(query)\n\n        # Calculate similarities\n        similarities = []\n        for i, doc_embedding in enumerate(self.embeddings):\n            similarity = cosine_similarity(query_embedding, doc_embedding)\n            similarities.append({\n                "document": self.documents[i],\n                "similarity": similarity\n            })\n\n        # Sort by similarity and return top K\n        similarities.sort(key=lambda x: x["similarity"], reverse=True)\n        return similarities[:top_k]\n\ndef main():\n    search = SemanticSearch()\n\n    # Index documents\n    search.index_documents(documents)\n    print()\n\n    # Test queries\n    queries = [\n        "How do neural networks work?",\n        "What is AI used for in images?",\n        "How can machines understand text?"\n    ]\n\n    for query in queries:\n        print(f\'Query: "{query}"\')\n        print("-" * 50)\n\n        results = search.search(query, top_k=2)\n\n        for result in results:\n            print(f"  {result[\'document\'][\'title\']}")\n            print(f"  Similarity: {result[\'similarity\'] * 100:.1f}%")\n            print()\n\nif __name__ == "__main__":\n    main()\n'})}),"\n",(0,s.jsx)(n.p,{children:"Run with:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"python semantic_search.py\n"})}),"\n",(0,s.jsx)(n.h2,{id:"step-4-advanced-usage",children:"Step 4: Advanced Usage"}),"\n",(0,s.jsx)(n.h3,{id:"rag-retrieval-augmented-generation",children:"RAG (Retrieval-Augmented Generation)"}),"\n",(0,s.jsx)(n.p,{children:"Combine embeddings with chat completions for RAG:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-javascript",metastring:'title="rag.js"',children:"import OpenAI from 'openai';\n\nconst client = new OpenAI({\n  baseURL: 'http://localhost:8083/mimik-ai/openai/v1',\n  apiKey: '1234'\n});\n\nasync function ragQuery(query) {\n  // 1. Find relevant documents (using SemanticSearch from earlier)\n  const results = await search.search(query, 3);\n\n  // 2. Build context from retrieved documents\n  const context = results\n    .map(r => `${r.document.title}: ${r.document.content}`)\n    .join('\\n\\n');\n\n  // 3. Generate response using context\n  const response = await client.chat.completions.create({\n    model: 'smollm2-360m',\n    messages: [\n      {\n        role: 'system',\n        content: `Answer questions based on the following context:\\n\\n${context}`\n      },\n      { role: 'user', content: query }\n    ]\n  });\n\n  return response.choices[0].message.content;\n}\n"})}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsx)(n.h3,{id:"empty-or-zero-embeddings",children:"Empty or Zero Embeddings"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Verify the model is ready (",(0,s.jsx)(n.code,{children:"readyToUse: true"}),")"]}),"\n",(0,s.jsxs)(n.li,{children:["Check that you're using ",(0,s.jsx)(n.code,{children:"kind: embed"})," for embedding models"]}),"\n",(0,s.jsx)(n.li,{children:"Ensure the input text is not empty"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"slow-embedding-generation",children:"Slow Embedding Generation"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"First request loads the model (expected)"}),"\n",(0,s.jsx)(n.li,{children:"Subsequent requests will be faster"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"different-embedding-dimensions",children:"Different Embedding Dimensions"}),"\n",(0,s.jsx)(n.p,{children:"Different models produce different embedding dimensions. Ensure you use the same model for both indexing and querying."}),"\n",(0,s.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/mimOE-devportal/docs/ai-foundation/examples/chat-smollm2",children:"Chat with SmolLM2"})}),":  Build a chat application"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/mimOE-devportal/docs/api/inference",children:"Inference API Reference"})}),":  Complete API documentation"]}),"\n"]})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453(e,n,i){i.d(n,{R:()=>r,x:()=>o});var t=i(6540);const s={},a=t.createContext(s);function r(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);