"use strict";(globalThis.webpackChunkmimoe_devportal=globalThis.webpackChunkmimoe_devportal||[]).push([[8144],{987(e,n,i){i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>a,frontMatter:()=>r,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ai-foundation/examples/finding-models","title":"Finding Models on Hugging Face","description":"Discover compatible GGUF and ONNX models on Hugging Face for on-device inference","source":"@site/docs/ai-foundation/examples/finding-models.md","sourceDirName":"ai-foundation/examples","slug":"/ai-foundation/examples/finding-models","permalink":"/mimOE-devportal/docs/ai-foundation/examples/finding-models","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5,"title":"Finding Models on Hugging Face","description":"Discover compatible GGUF and ONNX models on Hugging Face for on-device inference"},"sidebar":"aiFoundationSidebar","previous":{"title":"Semantic Search with Embeddings","permalink":"/mimOE-devportal/docs/ai-foundation/examples/semantic-search"},"next":{"title":"AI Development","permalink":"/mimOE-devportal/docs/ai-foundation/development/"}}');var l=i(4848),d=i(8453);const r={sidebar_position:5,title:"Finding Models on Hugging Face",description:"Discover compatible GGUF and ONNX models on Hugging Face for on-device inference"},t="Finding Models on Hugging Face",o={},c=[{value:"Understanding Model Formats",id:"understanding-model-formats",level:2},{value:"GGUF Models",id:"gguf-models",level:3},{value:"ONNX Models",id:"onnx-models",level:3},{value:"Finding GGUF Models",id:"finding-gguf-models",level:2},{value:"Method 1: Search with Filters",id:"method-1-search-with-filters",level:3},{value:"Method 2: Search by Keywords",id:"method-2-search-by-keywords",level:3},{value:"Popular GGUF Models for mimOE",id:"popular-gguf-models-for-mimoe",level:3},{value:"Small Models (2-4GB): Recommended for Most Devices",id:"small-models-2-4gb-recommended-for-most-devices",level:4},{value:"Medium Models (4-8GB): For Capable Devices",id:"medium-models-4-8gb-for-capable-devices",level:4},{value:"Understanding Quantization Levels",id:"understanding-quantization-levels",level:3},{value:"Downloading GGUF Models",id:"downloading-gguf-models",level:3},{value:"Finding ONNX Models",id:"finding-onnx-models",level:2},{value:"Method 1: Search with Filters",id:"method-1-search-with-filters-1",level:3},{value:"Method 2: Search by Task + &quot;ONNX&quot;",id:"method-2-search-by-task--onnx",level:3},{value:"Popular ONNX Models for mimOE",id:"popular-onnx-models-for-mimoe",level:3},{value:"Image Classification",id:"image-classification",level:4},{value:"Object Detection",id:"object-detection",level:4},{value:"Text Embeddings",id:"text-embeddings",level:4},{value:"Downloading ONNX Models",id:"downloading-onnx-models",level:3},{value:"Evaluating Models",id:"evaluating-models",level:2},{value:"Model Card",id:"model-card",level:3},{value:"Files Tab",id:"files-tab",level:3},{value:"Community Activity",id:"community-activity",level:3},{value:"Model Selection Criteria",id:"model-selection-criteria",level:2},{value:"For GGUF (Generative AI)",id:"for-gguf-generative-ai",level:3},{value:"For ONNX (Predictive AI)",id:"for-onnx-predictive-ai",level:3},{value:"Common Pitfalls to Avoid",id:"common-pitfalls-to-avoid",level:2},{value:"GGUF Models",id:"gguf-models-1",level:3},{value:"ONNX Models",id:"onnx-models-1",level:3},{value:"General",id:"general",level:3},{value:"Example Model Searches",id:"example-model-searches",level:2},{value:"&quot;I want a chatbot&quot;",id:"i-want-a-chatbot",level:3},{value:"&quot;I want to classify images&quot;",id:"i-want-to-classify-images",level:3},{value:"&quot;I want semantic search&quot;",id:"i-want-semantic-search",level:3},{value:"&quot;I want code completion&quot;",id:"i-want-code-completion",level:3},{value:"Next Steps",id:"next-steps",level:2},{value:"Resources",id:"resources",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,d.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(n.header,{children:(0,l.jsx)(n.h1,{id:"finding-models-on-hugging-face",children:"Finding Models on Hugging Face"})}),"\n",(0,l.jsx)(n.p,{children:"Hugging Face is the largest repository of AI models, with thousands of pre-trained models available for free. This guide shows you how to find compatible models for mimOE, evaluate their characteristics, and download them for on-device inference."}),"\n",(0,l.jsx)(n.h2,{id:"understanding-model-formats",children:"Understanding Model Formats"}),"\n",(0,l.jsx)(n.p,{children:"Before searching, understand which format you need:"}),"\n",(0,l.jsx)(n.h3,{id:"gguf-models",children:"GGUF Models"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Use when:"})," You need generative AI capabilities (chat, text generation, code completion)"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"File extension:"})," ",(0,l.jsx)(n.code,{children:".gguf"})]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Common use cases:"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Conversational AI"}),"\n",(0,l.jsx)(n.li,{children:"Text generation"}),"\n",(0,l.jsx)(n.li,{children:"Code completion"}),"\n",(0,l.jsx)(n.li,{children:"Question answering"}),"\n",(0,l.jsx)(n.li,{children:"Creative writing"}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Typical size:"})," 1.5GB - 8GB (quantized versions)"]}),"\n",(0,l.jsx)(n.h3,{id:"onnx-models",children:"ONNX Models"}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Use when:"})," You need predictive AI capabilities (classification, detection, embeddings)"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"File extension:"})," ",(0,l.jsx)(n.code,{children:".onnx"})]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Common use cases:"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Image classification"}),"\n",(0,l.jsx)(n.li,{children:"Object detection"}),"\n",(0,l.jsx)(n.li,{children:"Text embeddings"}),"\n",(0,l.jsx)(n.li,{children:"Sentiment analysis"}),"\n",(0,l.jsx)(n.li,{children:"Regression models"}),"\n"]}),"\n",(0,l.jsxs)(n.p,{children:[(0,l.jsx)(n.strong,{children:"Typical size:"})," 10MB - 500MB"]}),"\n",(0,l.jsx)(n.h2,{id:"finding-gguf-models",children:"Finding GGUF Models"}),"\n",(0,l.jsx)(n.h3,{id:"method-1-search-with-filters",children:"Method 1: Search with Filters"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["Go to ",(0,l.jsx)(n.a,{href:"https://huggingface.co/models",children:"Hugging Face Models"})]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["In the search filters, select:\n: ",(0,l.jsx)(n.strong,{children:"Format:"})," GGUF\n: ",(0,l.jsx)(n.strong,{children:"Libraries:"})," transformers (optional)\n: ",(0,l.jsx)(n.strong,{children:"Tasks:"})," Text Generation"]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["Sort by:\n: ",(0,l.jsx)(n.strong,{children:"Most downloads"}),": Popular, well-tested models\n: ",(0,l.jsx)(n.strong,{children:"Most likes"}),": Community favorites\n: ",(0,l.jsx)(n.strong,{children:"Trending"}),": Recently popular models"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"method-2-search-by-keywords",children:"Method 2: Search by Keywords"}),"\n",(0,l.jsx)(n.p,{children:"Use the search bar with specific keywords:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"phi-3 gguf\nllama-3 gguf\nmistral gguf\ngemma gguf\n"})}),"\n",(0,l.jsx)(n.h3,{id:"popular-gguf-models-for-mimoe",children:"Popular GGUF Models for mimOE"}),"\n",(0,l.jsx)(n.p,{children:"Here are recommended models that work well on-device:"}),"\n",(0,l.jsx)(n.h4,{id:"small-models-2-4gb-recommended-for-most-devices",children:"Small Models (2-4GB): Recommended for Most Devices"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size"}),(0,l.jsx)(n.th,{children:"Context"}),(0,l.jsx)(n.th,{children:"Best For"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Phi-3-mini-4k"})}),(0,l.jsx)(n.td,{children:"2.4GB (Q4)"}),(0,l.jsx)(n.td,{children:"4K tokens"}),(0,l.jsx)(n.td,{children:"General chat, coding, Q&A"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Gemma-2B"})}),(0,l.jsx)(n.td,{children:"1.8GB (Q4)"}),(0,l.jsx)(n.td,{children:"8K tokens"}),(0,l.jsx)(n.td,{children:"Fast responses, low memory"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"TinyLlama-1.1B"})}),(0,l.jsx)(n.td,{children:"0.6GB (Q4)"}),(0,l.jsx)(n.td,{children:"2K tokens"}),(0,l.jsx)(n.td,{children:"Ultra-fast, resource-constrained"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:"Direct links:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf",children:"Phi-3-mini-4k-instruct GGUF"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/google/gemma-2b-it-GGUF",children:"Gemma-2B GGUF"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",children:"TinyLlama-1.1B GGUF"})}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"medium-models-4-8gb-for-capable-devices",children:"Medium Models (4-8GB): For Capable Devices"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size"}),(0,l.jsx)(n.th,{children:"Context"}),(0,l.jsx)(n.th,{children:"Best For"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Llama-3-8B"})}),(0,l.jsx)(n.td,{children:"4.7GB (Q4)"}),(0,l.jsx)(n.td,{children:"8K tokens"}),(0,l.jsx)(n.td,{children:"High-quality responses"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Mistral-7B"})}),(0,l.jsx)(n.td,{children:"4.1GB (Q4)"}),(0,l.jsx)(n.td,{children:"8K tokens"}),(0,l.jsx)(n.td,{children:"Instruction following, reasoning"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Phi-3-medium"})}),(0,l.jsx)(n.td,{children:"7.6GB (Q4)"}),(0,l.jsx)(n.td,{children:"128K tokens"}),(0,l.jsx)(n.td,{children:"Long context, complex tasks"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:"Direct links:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF",children:"Llama-3-8B-Instruct GGUF"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF",children:"Mistral-7B-Instruct GGUF"})}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"understanding-quantization-levels",children:"Understanding Quantization Levels"}),"\n",(0,l.jsx)(n.p,{children:"GGUF models come in different quantization levels. Lower quantization = smaller size but slightly lower quality."}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Quantization"}),(0,l.jsx)(n.th,{children:"Size vs Original"}),(0,l.jsx)(n.th,{children:"Quality"}),(0,l.jsx)(n.th,{children:"Use When"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Q2"}),(0,l.jsx)(n.td,{children:"~25%"}),(0,l.jsx)(n.td,{children:"Acceptable"}),(0,l.jsx)(n.td,{children:"Extremely limited memory"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Q3"}),(0,l.jsx)(n.td,{children:"~33%"}),(0,l.jsx)(n.td,{children:"Good"}),(0,l.jsx)(n.td,{children:"Limited memory"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Q4"})}),(0,l.jsx)(n.td,{children:"~40%"}),(0,l.jsx)(n.td,{children:"Very Good"}),(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"Recommended default"})})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Q5"}),(0,l.jsx)(n.td,{children:"~50%"}),(0,l.jsx)(n.td,{children:"Excellent"}),(0,l.jsx)(n.td,{children:"You have extra memory"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Q6"}),(0,l.jsx)(n.td,{children:"~60%"}),(0,l.jsx)(n.td,{children:"Near-perfect"}),(0,l.jsx)(n.td,{children:"Quality is paramount"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:"Q8"}),(0,l.jsx)(n.td,{children:"~80%"}),(0,l.jsx)(n.td,{children:"Identical"}),(0,l.jsx)(n.td,{children:"Research/benchmarking"})]})]})]}),"\n",(0,l.jsx)(n.admonition,{title:"Recommended Quantization",type:"tip",children:(0,l.jsx)(n.p,{children:"Q4 (Q4_K_M variant) offers the best balance of size, speed, and quality for most use cases."})}),"\n",(0,l.jsx)(n.h3,{id:"downloading-gguf-models",children:"Downloading GGUF Models"}),"\n",(0,l.jsx)(n.p,{children:"Once you've found a model, download it:"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:'Option 1: Click "Download" on model page'})}),"\n",(0,l.jsxs)(n.p,{children:["Navigate to the Files tab and click the download icon next to the ",(0,l.jsx)(n.code,{children:".gguf"})," file."]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Option 2: Use curl (faster for large files)"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Example: Download Phi-3-mini Q4\ncurl -L -o phi-3-mini-4k-instruct-q4.gguf \\\n  "https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf?download=true"\n'})}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Option 3: Use Hugging Face CLI"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:"# Install HF CLI\npip install huggingface-hub\n\n# Download model\nhuggingface-cli download microsoft/Phi-3-mini-4k-instruct-gguf \\\n  Phi-3-mini-4k-instruct-q4.gguf \\\n  --local-dir ./models\n"})}),"\n",(0,l.jsx)(n.h2,{id:"finding-onnx-models",children:"Finding ONNX Models"}),"\n",(0,l.jsx)(n.h3,{id:"method-1-search-with-filters-1",children:"Method 1: Search with Filters"}),"\n",(0,l.jsxs)(n.ol,{children:["\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["Go to ",(0,l.jsx)(n.a,{href:"https://huggingface.co/models",children:"Hugging Face Models"})]}),"\n"]}),"\n",(0,l.jsxs)(n.li,{children:["\n",(0,l.jsxs)(n.p,{children:["In the search filters, select:\n: ",(0,l.jsx)(n.strong,{children:"Format:"})," ONNX\n: ",(0,l.jsx)(n.strong,{children:"Libraries:"})," transformers or onnx\n: ",(0,l.jsx)(n.strong,{children:"Tasks:"})," Select your task (Image Classification, Object Detection, etc.)"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"method-2-search-by-task--onnx",children:'Method 2: Search by Task + "ONNX"'}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{children:"mobilenet onnx\nresnet onnx\nbert onnx\nyolo onnx\n"})}),"\n",(0,l.jsx)(n.h3,{id:"popular-onnx-models-for-mimoe",children:"Popular ONNX Models for mimOE"}),"\n",(0,l.jsx)(n.h4,{id:"image-classification",children:"Image Classification"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size"}),(0,l.jsx)(n.th,{children:"Input Size"}),(0,l.jsx)(n.th,{children:"Accuracy"}),(0,l.jsx)(n.th,{children:"Speed"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"MobileNetV2"})}),(0,l.jsx)(n.td,{children:"14MB"}),(0,l.jsx)(n.td,{children:"224x224"}),(0,l.jsx)(n.td,{children:"72%"}),(0,l.jsx)(n.td,{children:"Very Fast"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"ResNet-50"})}),(0,l.jsx)(n.td,{children:"98MB"}),(0,l.jsx)(n.td,{children:"224x224"}),(0,l.jsx)(n.td,{children:"76%"}),(0,l.jsx)(n.td,{children:"Fast"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"EfficientNet-B0"})}),(0,l.jsx)(n.td,{children:"20MB"}),(0,l.jsx)(n.td,{children:"224x224"}),(0,l.jsx)(n.td,{children:"77%"}),(0,l.jsx)(n.td,{children:"Fast"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:"Direct links:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/onnx-community/mobilenet_v2_1.0_224",children:"MobileNetV2 ONNX"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/onnx-community/resnet-50",children:"ResNet-50 ONNX"})}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"object-detection",children:"Object Detection"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size"}),(0,l.jsx)(n.th,{children:"Input Size"}),(0,l.jsx)(n.th,{children:"Use Case"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"YOLOv8n"})}),(0,l.jsx)(n.td,{children:"6MB"}),(0,l.jsx)(n.td,{children:"640x640"}),(0,l.jsx)(n.td,{children:"Real-time detection (fast)"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"YOLOv8s"})}),(0,l.jsx)(n.td,{children:"22MB"}),(0,l.jsx)(n.td,{children:"640x640"}),(0,l.jsx)(n.td,{children:"Better accuracy"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"YOLOv8m"})}),(0,l.jsx)(n.td,{children:"52MB"}),(0,l.jsx)(n.td,{children:"640x640"}),(0,l.jsx)(n.td,{children:"High accuracy"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:"Direct links:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/models?search=yolov8+onnx",children:"YOLOv8 ONNX models"})}),"\n"]}),"\n",(0,l.jsx)(n.h4,{id:"text-embeddings",children:"Text Embeddings"}),"\n",(0,l.jsxs)(n.table,{children:[(0,l.jsx)(n.thead,{children:(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.th,{children:"Model"}),(0,l.jsx)(n.th,{children:"Size"}),(0,l.jsx)(n.th,{children:"Embedding Dim"}),(0,l.jsx)(n.th,{children:"Use Case"})]})}),(0,l.jsxs)(n.tbody,{children:[(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"all-MiniLM-L6-v2"})}),(0,l.jsx)(n.td,{children:"90MB"}),(0,l.jsx)(n.td,{children:"384"}),(0,l.jsx)(n.td,{children:"Fast semantic search"})]}),(0,l.jsxs)(n.tr,{children:[(0,l.jsx)(n.td,{children:(0,l.jsx)(n.strong,{children:"BERT-base"})}),(0,l.jsx)(n.td,{children:"420MB"}),(0,l.jsx)(n.td,{children:"768"}),(0,l.jsx)(n.td,{children:"Higher quality embeddings"})]})]})]}),"\n",(0,l.jsx)(n.p,{children:"Direct links:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2",children:"all-MiniLM-L6-v2 ONNX"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/onnx-community/bert-base-uncased",children:"BERT-base ONNX"})}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"downloading-onnx-models",children:"Downloading ONNX Models"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Option 1: Direct download"})}),"\n",(0,l.jsx)(n.p,{children:'Click "Download" on the model\'s Files tab.'}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Option 2: Use curl"})}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-bash",children:'# Example: Download MobileNetV2\ncurl -L -o mobilenet_v2.onnx \\\n  "https://huggingface.co/onnx-community/mobilenet_v2_1.0_224/resolve/main/model.onnx?download=true"\n'})}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"Option 3: Python script to export"})}),"\n",(0,l.jsx)(n.p,{children:"Many models don't have pre-exported ONNX versions. You can export them:"}),"\n",(0,l.jsx)(n.pre,{children:(0,l.jsx)(n.code,{className:"language-python",children:'from transformers import AutoModel\nfrom optimum.onnxruntime import ORTModelForImageClassification\n\n# Load and export to ONNX\nmodel = ORTModelForImageClassification.from_pretrained(\n    "microsoft/resnet-50",\n    export=True\n)\nmodel.save_pretrained("./resnet-50-onnx")\n'})}),"\n",(0,l.jsx)(n.h2,{id:"evaluating-models",children:"Evaluating Models"}),"\n",(0,l.jsx)(n.p,{children:"Before downloading, check these characteristics:"}),"\n",(0,l.jsx)(n.h3,{id:"model-card",children:"Model Card"}),"\n",(0,l.jsx)(n.p,{children:'Every model has a "Model Card" describing:'}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Purpose"}),": What the model is designed for"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Training data"}),": What data it was trained on"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Limitations"}),": Known weaknesses"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"License"}),": Usage restrictions"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"files-tab",children:"Files Tab"}),"\n",(0,l.jsx)(n.p,{children:"Check the model's files:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Size"}),": Will it fit in your available memory?"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Format"}),": Is it ",(0,l.jsx)(n.code,{children:".gguf"})," or ",(0,l.jsx)(n.code,{children:".onnx"}),"?"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Variants"}),": Multiple quantization levels available?"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"community-activity",children:"Community Activity"}),"\n",(0,l.jsx)(n.p,{children:"Indicators of model quality:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Downloads"}),": More downloads = more tested"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Likes"}),": Community endorsement"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Discussions"}),": Active community support"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Recent updates"}),": Is it maintained?"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"model-selection-criteria",children:"Model Selection Criteria"}),"\n",(0,l.jsx)(n.h3,{id:"for-gguf-generative-ai",children:"For GGUF (Generative AI)"}),"\n",(0,l.jsx)(n.p,{children:"Choose based on:"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"1. Memory constraints"})}),"\n",(0,l.jsx)(n.p,{children:"Rule of thumb: You need ~1.5-2x the model file size in available RAM."}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"4GB RAM \u2192 Up to 2B parameters (TinyLlama 1.1B, Gemma-2B)"}),"\n",(0,l.jsx)(n.li,{children:"8GB RAM \u2192 Up to 4B parameters (Phi-3-mini, SmolLM2)"}),"\n",(0,l.jsx)(n.li,{children:"16GB RAM \u2192 Up to 7B parameters comfortably (Llama-3-8B, Mistral-7B)"}),"\n",(0,l.jsx)(n.li,{children:"32GB RAM \u2192 Up to 13B parameters (Llama-3-13B, CodeLlama-13B)"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"2. Task complexity"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Simple chat \u2192 Phi-3-mini, Gemma-2B"}),"\n",(0,l.jsx)(n.li,{children:"Code generation \u2192 Phi-3-mini, CodeLlama"}),"\n",(0,l.jsx)(n.li,{children:"Long documents \u2192 Phi-3-medium (128K context)"}),"\n",(0,l.jsx)(n.li,{children:"Maximum quality \u2192 Llama-3-8B, Mistral-7B"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"3. Response speed"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Fastest \u2192 TinyLlama (0.6GB)"}),"\n",(0,l.jsx)(n.li,{children:"Fast \u2192 Phi-3-mini (2.4GB)"}),"\n",(0,l.jsx)(n.li,{children:"Balanced \u2192 Llama-3-8B Q4 (4.7GB)"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"for-onnx-predictive-ai",children:"For ONNX (Predictive AI)"}),"\n",(0,l.jsx)(n.p,{children:"Choose based on:"}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"1. Task type"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Image classification \u2192 MobileNetV2, ResNet-50"}),"\n",(0,l.jsx)(n.li,{children:"Object detection \u2192 YOLOv8n, YOLOv8s"}),"\n",(0,l.jsx)(n.li,{children:"Text embeddings \u2192 all-MiniLM-L6-v2"}),"\n",(0,l.jsx)(n.li,{children:"Sentiment analysis \u2192 DistilBERT"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"2. Accuracy vs. Speed"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Speed priority \u2192 MobileNetV2, YOLOv8n, MiniLM"}),"\n",(0,l.jsx)(n.li,{children:"Accuracy priority \u2192 ResNet-50, YOLOv8m, BERT-base"}),"\n",(0,l.jsx)(n.li,{children:"Balanced \u2192 EfficientNet-B0, YOLOv8s"}),"\n"]}),"\n",(0,l.jsx)(n.p,{children:(0,l.jsx)(n.strong,{children:"3. Input constraints"})}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Limited preprocessing \u2192 Models with 224x224 input"}),"\n",(0,l.jsx)(n.li,{children:"High resolution \u2192 Models with 640x640+ input"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"common-pitfalls-to-avoid",children:"Common Pitfalls to Avoid"}),"\n",(0,l.jsx)(n.h3,{id:"gguf-models-1",children:"GGUF Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Don't download multiple quantizations"}),": Pick one (Q4 recommended)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Check context length"}),": Longer isn't always better (more memory)"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Verify it's an instruct model"}),": Base models aren't fine-tuned for chat"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"onnx-models-1",children:"ONNX Models"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Check input preprocessing"}),": Must match model expectations"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Verify output format"}),": Some models return logits, others probabilities"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Look for complete examples"}),": Preprocessing is critical"]}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"general",children:"General"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Read the license"}),": Some models have commercial restrictions"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Check file integrity"}),": Large downloads can get corrupted"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:"Test on sample data first"}),": Before deploying"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"example-model-searches",children:"Example Model Searches"}),"\n",(0,l.jsx)(n.h3,{id:"i-want-a-chatbot",children:'"I want a chatbot"'}),"\n",(0,l.jsxs)(n.p,{children:["Search: ",(0,l.jsx)(n.code,{children:"phi-3 gguf"})," or ",(0,l.jsx)(n.code,{children:"llama-3 gguf"})]}),"\n",(0,l.jsxs)(n.p,{children:["Recommendation: ",(0,l.jsx)(n.strong,{children:"Phi-3-mini-4k-instruct Q4"})," (2.4GB)"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Fast responses"}),"\n",(0,l.jsx)(n.li,{children:"Good quality"}),"\n",(0,l.jsx)(n.li,{children:"Works on most devices"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"i-want-to-classify-images",children:'"I want to classify images"'}),"\n",(0,l.jsxs)(n.p,{children:["Search: ",(0,l.jsx)(n.code,{children:"mobilenet onnx"})," or ",(0,l.jsx)(n.code,{children:"resnet onnx"})]}),"\n",(0,l.jsxs)(n.p,{children:["Recommendation: ",(0,l.jsx)(n.strong,{children:"MobileNetV2 ONNX"})," (14MB)"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Very fast"}),"\n",(0,l.jsx)(n.li,{children:"Good accuracy for common objects"}),"\n",(0,l.jsx)(n.li,{children:"Small size"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"i-want-semantic-search",children:'"I want semantic search"'}),"\n",(0,l.jsxs)(n.p,{children:["Search: ",(0,l.jsx)(n.code,{children:"sentence-transformers onnx"})," or ",(0,l.jsx)(n.code,{children:"all-MiniLM onnx"})]}),"\n",(0,l.jsxs)(n.p,{children:["Recommendation: ",(0,l.jsx)(n.strong,{children:"all-MiniLM-L6-v2"})," (90MB)"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Fast embedding generation"}),"\n",(0,l.jsx)(n.li,{children:"Good semantic understanding"}),"\n",(0,l.jsx)(n.li,{children:"Widely used and tested"}),"\n"]}),"\n",(0,l.jsx)(n.h3,{id:"i-want-code-completion",children:'"I want code completion"'}),"\n",(0,l.jsxs)(n.p,{children:["Search: ",(0,l.jsx)(n.code,{children:"phi-3 gguf"})," or ",(0,l.jsx)(n.code,{children:"codellama gguf"})]}),"\n",(0,l.jsxs)(n.p,{children:["Recommendation: ",(0,l.jsx)(n.strong,{children:"Phi-3-mini-4k-instruct Q4"})," (2.4GB)"]}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:"Excellent coding capabilities"}),"\n",(0,l.jsx)(n.li,{children:"Fast"}),"\n",(0,l.jsx)(n.li,{children:"Reasonable size"}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,l.jsx)(n.p,{children:"Now that you know how to find models:"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/mimOE-devportal/docs/ai-foundation/quick-start",children:"Quick Start"})}),": Upload your first model"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/mimOE-devportal/docs/ai-foundation/examples/chat-smollm2",children:"Chat with SmolLM2"})}),": Complete GGUF tutorial"]}),"\n",(0,l.jsxs)(n.li,{children:[(0,l.jsx)(n.strong,{children:(0,l.jsx)(n.a,{href:"/mimOE-devportal/docs/ai-foundation/upload-model",children:"Upload Models"})}),": Detailed upload guide"]}),"\n"]}),"\n",(0,l.jsx)(n.h2,{id:"resources",children:"Resources"}),"\n",(0,l.jsxs)(n.ul,{children:["\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/models",children:"Hugging Face Models Hub"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://github.com/ggerganov/ggml/blob/master/docs/gguf.md",children:"GGUF Format Documentation"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://github.com/onnx/models",children:"ONNX Model Zoo"})}),"\n",(0,l.jsx)(n.li,{children:(0,l.jsx)(n.a,{href:"https://huggingface.co/docs/transformers/main/en/quantization",children:"Model Quantization Guide"})}),"\n"]})]})}function a(e={}){const{wrapper:n}={...(0,d.R)(),...e.components};return n?(0,l.jsx)(n,{...e,children:(0,l.jsx)(h,{...e})}):h(e)}},8453(e,n,i){i.d(n,{R:()=>r,x:()=>t});var s=i(6540);const l={},d=s.createContext(l);function r(e){const n=s.useContext(d);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),s.createElement(d.Provider,{value:n},e.children)}}}]);